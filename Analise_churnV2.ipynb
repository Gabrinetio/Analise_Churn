{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wYexwJLHaaefQGG-HNjQYhpTBlRuJs5O",
      "authorship_tag": "ABX9TyOuqZvIZ0Vj0lgTztETDKUE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabrinetio/Colab/blob/main/Analise_churnV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação rápida do Plotly Express\n",
        "try:\n",
        "    import plotly\n",
        "    import plotly.express as px\n",
        "    print(\"Plotly instalado com sucesso.\")\n",
        "    print(\"Versão do plotly:\", plotly.__version__)\n",
        "    # teste rápido de criação de figura (não mostra, apenas cria)\n",
        "    import pandas as pd\n",
        "    df_tmp = pd.DataFrame({\"x\": [1,2,3], \"y\": [1,4,9]})\n",
        "    fig = px.line(df_tmp, x=\"x\", y=\"y\", title=\"Teste Plotly Express\")\n",
        "    print(\"Figura criada com sucesso (px.line)\")\n",
        "except Exception as e:\n",
        "    import sys\n",
        "    print(\"Falha ao importar/usar plotly.express:\", e)\n",
        "    print(\"Python:\", sys.version)"
      ],
      "metadata": {
        "id": "F-KCYL6220N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação rápida do Plotly Express\n",
        "try:\n",
        "    import plotly\n",
        "    import plotly.express as px\n",
        "    print(\"Plotly instalado com sucesso.\")\n",
        "    print(\"Versão do plotly:\", plotly.__version__)\n",
        "    # teste rápido de criação de figura (não mostra, apenas cria)\n",
        "    import pandas as pd\n",
        "    df_tmp = pd.DataFrame({\"x\": [1,2,3], \"y\": [1,4,9]})\n",
        "    fig = px.line(df_tmp, x=\"x\", y=\"y\", title=\"Teste Plotly Express\")\n",
        "    print(\"Figura criada com sucesso (px.line)\")\n",
        "except Exception as e:\n",
        "    import sys\n",
        "    print(\"Falha ao importar/usar plotly.express:\", e)\n",
        "    print(\"Python:\", sys.version)"
      ],
      "metadata": {
        "id": "VLgeTxSm238L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação do IProgress (ipywidgets)\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "\n",
        "progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0, description='Carregando:', bar_style='info')\n",
        "display(progress)\n",
        "for i in range(100):\n",
        "    progress.value = (i + 1) / 100.0\n",
        "    time.sleep(0.01)\n",
        "progress.bar_style = 'success'\n",
        "print('IProgress (ipywidgets) ok!')"
      ],
      "metadata": {
        "id": "kFg2riSj3G4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 1: Importações e Carga dos Dados\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carregue o arquivo CSV que você baixou\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# Visualizar as primeiras linhas e informações gerais\n",
        "print(\"Amostra dos Dados:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nInformações Gerais do DataFrame:\")\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "8psdefRxR0Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2: Tradução dos Dados para Português\n",
        "\n",
        "print(\"Iniciando a tradução dos dados...\")\n",
        "\n",
        "# 1. Dicionário para traduzir os NOMES DAS COLUNAS\n",
        "colunas_traducao = {\n",
        "    'customerID': 'ID_Cliente',\n",
        "    'gender': 'Gênero',\n",
        "    'SeniorCitizen': 'Idoso',\n",
        "    'Partner': 'Possui_Parceiro',\n",
        "    'Dependents': 'Possui_Dependentes',\n",
        "    'tenure': 'Tempo_de_Contrato_Meses',\n",
        "    'PhoneService': 'Serviço_Telefônico',\n",
        "    'MultipleLines': 'Múltiplas_Linhas',\n",
        "    'InternetService': 'Serviço_de_Internet',\n",
        "    'OnlineSecurity': 'Segurança_Online',\n",
        "    'OnlineBackup': 'Backup_Online',\n",
        "    'DeviceProtection': 'Proteção_de_Aparelho',\n",
        "    'TechSupport': 'Suporte_Técnico',\n",
        "    'StreamingTV': 'Streaming_de_TV',\n",
        "    'StreamingMovies': 'Streaming_de_Filmes',\n",
        "    'Contract': 'Tipo_de_Contrato',\n",
        "    'PaperlessBilling': 'Fatura_Digital',\n",
        "    'PaymentMethod': 'Método_de_Pagamento',\n",
        "    'MonthlyCharges': 'Cobrança_Mensal',\n",
        "    'TotalCharges': 'Cobrança_Total',\n",
        "    'Churn': 'Churn'\n",
        "}\n",
        "\n",
        "# 2. Traduzindo os VALORES DENTRO das colunas categóricas\n",
        "# Gênero\n",
        "df['gender'].replace({'Male': 'Masculino', 'Female': 'Feminino'}, inplace=True)\n",
        "\n",
        "# Mapeamento simples de Sim/Não para várias colunas\n",
        "colunas_sim_nao = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
        "for coluna in colunas_sim_nao:\n",
        "    df[coluna].replace({'Yes': 'Sim', 'No': 'Não'}, inplace=True)\n",
        "\n",
        "# Mapeamentos específicos\n",
        "df['MultipleLines'].replace({'No phone service': 'Sem serviço telefônico'}, inplace=True)\n",
        "df['MultipleLines'].replace({'Yes': 'Sim', 'No': 'Não'}, inplace=True)\n",
        "\n",
        "df['InternetService'].replace({'Fiber optic': 'Fibra Ótica', 'No': 'Não'}, inplace=True)\n",
        "\n",
        "colunas_servico_internet = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
        "for coluna in colunas_servico_internet:\n",
        "    df[coluna].replace({'No internet service': 'Sem serviço de internet'}, inplace=True)\n",
        "    df[coluna].replace({'Yes': 'Sim', 'No': 'Não'}, inplace=True)\n",
        "\n",
        "df['Contract'].replace({'Month-to-month': 'Mês a Mês', 'One year': 'Anual', 'Two year': 'Dois Anos'}, inplace=True)\n",
        "\n",
        "df['PaymentMethod'].replace({\n",
        "    'Electronic check': 'Cheque Eletrônico',\n",
        "    'Mailed check': 'Cheque Enviado',\n",
        "    'Bank transfer (automatic)': 'Transferência Bancária (Automática)',\n",
        "    'Credit card (automatic)': 'Cartão de Crédito (Automático)'\n",
        "}, inplace=True)\n",
        "\n",
        "# Idoso (de 0/1 para Não/Sim para melhor visualização)\n",
        "df['SeniorCitizen'].replace({0: 'Não', 1: 'Sim'}, inplace=True)\n",
        "\n",
        "\n",
        "# 3. Aplicando a tradução nos NOMES DAS COLUNAS como passo final\n",
        "df.rename(columns=colunas_traducao, inplace=True)\n",
        "\n",
        "\n",
        "# Verificação: Exibir as primeiras linhas e os valores únicos de uma coluna traduzida\n",
        "print(\"\\nTradução concluída! Amostra dos dados traduzidos:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nExemplo de valores únicos na coluna 'Tipo_de_Contrato':\")\n",
        "print(df['Tipo_de_Contrato'].unique())"
      ],
      "metadata": {
        "id": "yKbiUZlaR5Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3: Limpeza Pós-Tradução\n",
        "# A coluna agora se chama 'Cobrança_Total'\n",
        "df['Cobrança_Total'] = pd.to_numeric(df['Cobrança_Total'], errors='coerce')\n",
        "\n",
        "print(\"Valores nulos antes do tratamento:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Preencher os nulos com a mediana\n",
        "df['Cobrança_Total'].fillna(df['Cobrança_Total'].median(), inplace=True)\n",
        "\n",
        "print(\"\\nValores nulos depois do tratamento:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Ff2Z7x14hQDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4 (VERSÃO FINAL): Preparação dos Dados Mantendo o ID\n",
        "\n",
        "# 1. Transformar a coluna alvo para formato numérico\n",
        "df['Churn'] = df['Churn'].map({'Não': 0, 'Sim': 1})\n",
        "\n",
        "# A LINHA QUE APAGAVA O ID FOI REMOVIDA DAQUI.\n",
        "# O 'df' principal agora mantém a coluna 'ID_Cliente'.\n",
        "\n",
        "# 2. Separamos as features (X) e o alvo (y)\n",
        "# IMPORTANTE: Aqui garantimos que o ID não seja usado como uma feature de treino\n",
        "X = df.drop(columns=['Churn', 'ID_Cliente'])\n",
        "y = df['Churn']\n",
        "\n",
        "# 3. Codificar as variáveis categóricas das features (X)\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# --- Verificações ---\n",
        "print(\"VERIFICAÇÃO IMPORTANTE:\")\n",
        "print(\"Valores únicos no alvo 'y' após a conversão:\", y.unique())\n",
        "\n",
        "print(\"\\nO DataFrame 'df' ainda contém o ID_Cliente?\")\n",
        "print('ID_Cliente' in df.columns) # A SAÍDA DEVE SER True\n",
        "\n",
        "display(X_encoded.head())"
      ],
      "metadata": {
        "id": "ph6kEQhnhV6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5: Divisão e Padronização dos Dados\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Dividir em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Padronizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Dados divididos e padronizados com sucesso!\") # Adicione um print para confirmar\n"
      ],
      "metadata": {
        "id": "5udHwnFwhaYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6 (VERSÃO MELHORADA): Treinando Modelos com Peso de Classe Balanceado\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "print(\"Treinando modelos com o parâmetro class_weight='balanced'...\\n\")\n",
        "\n",
        "# --- Modelo 1: Regressão Logística (Balanceada) ---\n",
        "modelo_log_bal = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
        "modelo_log_bal.fit(X_train_scaled, y_train)\n",
        "y_pred_log_bal = modelo_log_bal.predict(X_test_scaled)\n",
        "\n",
        "print(\"--- Regressão Logística (Balanceada) ---\")\n",
        "print(f\"Acurácia: {accuracy_score(y_test, y_pred_log_bal):.2%}\")\n",
        "print(classification_report(y_test, y_pred_log_bal))\n",
        "\n",
        "\n",
        "# --- Modelo 2: Random Forest (Balanceado) ---\n",
        "modelo_rf_bal = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "modelo_rf_bal.fit(X_train, y_train)\n",
        "y_pred_rf_bal = modelo_rf_bal.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Random Forest (Balanceada) ---\")\n",
        "print(f\"Acurácia: {accuracy_score(y_test, y_pred_rf_bal):.2%}\")\n",
        "print(classification_report(y_test, y_pred_rf_bal))"
      ],
      "metadata": {
        "id": "3x4R-DH0hf8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 7: Otimização de Hiperparâmetros\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "print(\"Iniciando a busca pelos melhores hiperparâmetros para o Random Forest...\")\n",
        "\n",
        "# 1. Definir o espaço de parâmetros para testar\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# 2. Criar o modelo base que será otimizado\n",
        "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# 3. É ESTA LINHA QUE CRIA a variável 'random_search'\n",
        "# Ela configura a busca aleatória.\n",
        "# n_iter=50 testa 50 combinações, cv=3 usa validação cruzada\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
        "                                   n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1,\n",
        "                                   scoring='recall') # Vamos otimizar para 'recall'\n",
        "\n",
        "# 4. AGORA SIM, EXECUTAR a busca (pode levar alguns minutos)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# 5. Mostrar os melhores parâmetros encontrados\n",
        "print(\"\\nMelhores parâmetros encontrados:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# 6. Avaliar o melhor modelo encontrado pela busca\n",
        "best_rf_model = random_search.best_estimator_\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Performance do Melhor Random Forest Otimizado ---\")\n",
        "print(classification_report(y_test, y_pred_best_rf))"
      ],
      "metadata": {
        "id": "bzxzgFVzhjXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 8: Treinando com XGBoost\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Treinando o modelo XGBoost...\")\n",
        "\n",
        "# O XGBoost tem uma forma própria e eficaz de lidar com dados desbalanceados: scale_pos_weight\n",
        "# Calculamos a proporção entre a classe majoritária (0) e a minoritária (1)\n",
        "escala = df['Churn'].value_counts()[0] / df['Churn'].value_counts()[1]\n",
        "\n",
        "# Criar o modelo XGBClassifier com parâmetros importantes\n",
        "# objective='binary:logistic': especificamos que é um problema de classificação binária.\n",
        "# scale_pos_weight=escala: aqui informamos ao modelo sobre o desbalanceamento.\n",
        "modelo_xgb = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    scale_pos_weight=escala,\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_xgb = modelo_xgb.predict(X_test)\n",
        "\n",
        "# Avaliar a performance\n",
        "print(\"\\n--- Performance do XGBoost ---\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "id": "RRj0uPmNhmVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 9: Comparação Visual com Curva ROC e AUC\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Gerando a Curva ROC para comparar os melhores modelos...\")\n",
        "\n",
        "# 1. Obter as probabilidades de previsão para a classe 1 (Churn)\n",
        "prob_log_bal = modelo_log_bal.predict_proba(X_test_scaled)[:, 1]\n",
        "prob_best_rf = best_rf_model.predict_proba(X_test)[:, 1]\n",
        "prob_xgb = modelo_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 2. Calcular a AUC para cada modelo\n",
        "auc_log_bal = roc_auc_score(y_test, prob_log_bal)\n",
        "auc_best_rf = roc_auc_score(y_test, prob_best_rf)\n",
        "auc_xgb = roc_auc_score(y_test, prob_xgb)\n",
        "\n",
        "print(f\"\\nAUC Regressão Logística Balanceada: {auc_log_bal:.4f}\")\n",
        "print(f\"AUC Random Forest Otimizado: {auc_best_rf:.4f}\")\n",
        "print(f\"AUC XGBoost: {auc_xgb:.4f}\")\n",
        "\n",
        "# 3. Calcular os pontos da Curva ROC\n",
        "fpr_log_bal, tpr_log_bal, _ = roc_curve(y_test, prob_log_bal)\n",
        "fpr_best_rf, tpr_best_rf, _ = roc_curve(y_test, prob_best_rf)\n",
        "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, prob_xgb)\n",
        "\n",
        "# 4. Plotar o gráfico\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_log_bal, tpr_log_bal, label=f'Reg. Logística (AUC = {auc_log_bal:.3f})')\n",
        "plt.plot(fpr_best_rf, tpr_best_rf, label=f'Random Forest Otimizado (AUC = {auc_best_rf:.3f})')\n",
        "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.3f})', linewidth=2.5)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Modelo Aleatório') # Linha de referência\n",
        "\n",
        "plt.title('Curva ROC - Comparação de Modelos para Previsão de Churn', fontsize=16)\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (Recall)')\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uzdgaqyxhpmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 10: Gerando a Lista de Ação com ID do Cliente\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Identificando os 10 clientes com maior probabilidade de Churn...\")\n",
        "\n",
        "# 1. Usar o nosso melhor modelo para prever as PROBABILIDADES\n",
        "probabilidades = best_rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 2. Esta linha agora funciona, pois 'df' contém o 'ID_Cliente'\n",
        "df_resultados = df.loc[X_test.index].copy()\n",
        "df_resultados['Probabilidade_Churn'] = probabilidades\n",
        "\n",
        "# 3. Ordenar o DataFrame pela probabilidade de Churn\n",
        "df_resultados_ordenado = df_resultados.sort_values(by='Probabilidade_Churn', ascending=False)\n",
        "\n",
        "# 4. Adicionar o 'ID_Cliente' à lista de colunas relevantes\n",
        "colunas_relevantes = [\n",
        "    'ID_Cliente',\n",
        "    'Probabilidade_Churn',\n",
        "    'Tempo_de_Contrato_Meses',\n",
        "    'Tipo_de_Contrato',\n",
        "    'Cobrança_Mensal',\n",
        "    'Cobrança_Total',\n",
        "    'Serviço_de_Internet'\n",
        "]\n",
        "\n",
        "# 5. Exibir a lista final e acionável\n",
        "print(\"\\n--- LISTA DE AÇÃO: Top 10 Clientes com Maior Risco de Cancelamento ---\")\n",
        "display(df_resultados_ordenado[colunas_relevantes].head(10))\n"
      ],
      "metadata": {
        "id": "YBJTS2SKh2SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 11: Análise de Churn por Segmento de Valor\n",
        "\n",
        "print(\"Analisando o risco de churn por segmento de valor do cliente...\")\n",
        "\n",
        "# Usar o DataFrame de resultados que já criamos na Célula 10\n",
        "# Criar segmentos de valor baseados na Cobrança Mensal (Ex: dividindo em 4 grupos)\n",
        "df_resultados_ordenado['Segmento_Valor'] = pd.qcut(\n",
        "    df_resultados_ordenado['Cobrança_Mensal'],\n",
        "    q=4,\n",
        "    labels=['Baixo', 'Médio', 'Alto', 'Premium']\n",
        ")\n",
        "\n",
        "# Filtrar para ver apenas os clientes com probabilidade de churn acima de 50%\n",
        "clientes_em_risco = df_resultados_ordenado[df_resultados_ordenado['Probabilidade_Churn'] > 0.5]\n",
        "\n",
        "# Contar quantos clientes em risco temos em cada segmento\n",
        "churn_por_segmento = clientes_em_risco['Segmento_Valor'].value_counts()\n",
        "\n",
        "print(\"\\nDistribuição de clientes em risco de churn por segmento de valor:\")\n",
        "print(churn_por_segmento)\n",
        "\n",
        "# Gerar a lista de ação para o segmento mais valioso\n",
        "print(\"\\n--- LISTA DE AÇÃO PRIORITÁRIA: Top 10 Clientes 'Premium' em Risco de Churn ---\")\n",
        "display(\n",
        "    clientes_em_risco[clientes_em_risco['Segmento_Valor'] == 'Premium']\n",
        "    [['ID_Cliente', 'Probabilidade_Churn', 'Cobrança_Mensal', 'Tempo_de_Contrato_Meses']]\n",
        "    .head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "hYGFfLaoh3Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 12: Calculando o Impacto Financeiro (MRR em Risco)\n",
        "\n",
        "# Usar o DataFrame de clientes em risco que criamos na célula anterior\n",
        "mrr_em_risco_total = clientes_em_risco['Cobrança_Mensal'].sum()\n",
        "\n",
        "# Calcular o MRR em risco apenas dos clientes 'Premium' e 'Alto'\n",
        "mrr_alto_valor_risco = clientes_em_risco[\n",
        "    clientes_em_risco['Segmento_Valor'].isin(['Alto', 'Premium'])\n",
        "]['Cobrança_Mensal'].sum()\n",
        "\n",
        "\n",
        "print(f\"\\n--- Análise de Impacto Financeiro ---\")\n",
        "print(f\"Receita Mensal Recorrente (MRR) Total em Risco: R$ {mrr_em_risco_total:.2f}\")\n",
        "print(f\"MRR em Risco de Clientes de Alto Valor e Premium: R$ {mrr_alto_valor_risco:.2f}\")\n"
      ],
      "metadata": {
        "id": "4SoVxmGph91i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 13 (VERSÃO CORRIGIDA): Análise Causa-Raiz no Segmento 'Mês a Mês'\n",
        "\n",
        "# Usamos 'df' em vez de 'df_original'\n",
        "df_mes_a_mes = df[df['Tipo_de_Contrato'] == 'Mês a Mês']\n",
        "\n",
        "# Comparamos o perfil dos que cancelaram vs. os que ficaram DENTRO deste segmento\n",
        "# Usamos Churn == 1 para 'Sim' e Churn == 0 para 'Não'\n",
        "perfil_churn_mes_a_mes = df_mes_a_mes[df_mes_a_mes['Churn'] == 1].describe()\n",
        "perfil_ficam_mes_a_mes = df_mes_a_mes[df_mes_a_mes['Churn'] == 0].describe()\n",
        "\n",
        "print(\"\\n--- Análise: Perfil de Clientes com Contrato 'Mês a Mês' ---\")\n",
        "print(\"\\nPerfil médio de quem CANCELOU:\")\n",
        "display(perfil_churn_mes_a_mes[['Tempo_de_Contrato_Meses', 'Cobrança_Mensal']])\n",
        "\n",
        "print(\"\\nPerfil médio de quem FICOU:\")\n",
        "display(perfil_ficam_mes_a_mes[['Tempo_de_Contrato_Meses', 'Cobrança_Mensal']])\n"
      ],
      "metadata": {
        "id": "rNcn9pgciHgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 14: Célula para Relatório: Usando Plotly para Gráficos Interativos\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Reutilizar o cálculo que já fizemos\n",
        "churn_por_pagamento = df.groupby('Método_de_Pagamento')['Churn'].mean().sort_values(ascending=False) * 100\n",
        "df_plot = churn_por_pagamento.reset_index()\n",
        "\n",
        "# Criar o gráfico com Plotly Express\n",
        "fig = px.bar(\n",
        "    df_plot,\n",
        "    x='Método_de_Pagamento',\n",
        "    y='Churn',\n",
        "    title='Taxa de Churn por Método de Pagamento',\n",
        "    labels={'Churn': 'Taxa de Churn (%)', 'Método_de_Pagamento': 'Método de Pagamento'},\n",
        "    text_auto='.2f' # Formata o texto para 2 casas decimais\n",
        ")\n",
        "\n",
        "# Melhorar o layout\n",
        "fig.update_layout(\n",
        "    title_font_size=22,\n",
        "    xaxis_title_font_size=16,\n",
        "    yaxis_title_font_size=16,\n",
        ")\n",
        "\n",
        "# Exibir o gráfico interativo\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "1UcNrCEhiMZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 15: Análise da Taxa de Churn pela Jornada do Cliente (Tempo de Contrato)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Analisando a taxa de churn em diferentes estágios da jornada do cliente...\")\n",
        "\n",
        "# Criar \"faixas\" de tempo de contrato para agrupar os clientes\n",
        "bins = [0, 12, 24, 36, 48, 60, 72]\n",
        "labels = ['0-12 Meses', '13-24 Meses', '25-36 Meses', '37-48 Meses', '49-60 Meses', '61-72 Meses']\n",
        "df['Faixa_de_Contrato'] = pd.cut(df['Tempo_de_Contrato_Meses'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Calcular a taxa de churn para cada faixa\n",
        "churn_por_jornada = df.groupby('Faixa_de_Contrato')['Churn'].mean().sort_index() * 100\n",
        "\n",
        "print(\"\\n--- Taxa de Churn (%) por Tempo de Contrato ---\")\n",
        "print(churn_por_jornada.round(2))\n",
        "\n",
        "# Visualizar os resultados\n",
        "plt.figure(figsize=(12, 7))\n",
        "ax = sns.barplot(x=churn_por_jornada.index, y=churn_por_jornada.values, palette='coolwarm')\n",
        "plt.title('Taxa de Churn ao Longo da Jornada do Cliente', fontsize=16)\n",
        "plt.ylabel('Taxa de Churn (%)')\n",
        "plt.xlabel('Tempo de Contrato com a Empresa')\n",
        "\n",
        "# Adicionar os valores no topo das barras para clareza\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f\"{p.get_height():.1f}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0CWw5v0hiOZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 16: Análise de Receita por Tipo de Contrato\n",
        "\n",
        "print(\"Analisando a receita e o churn por tipo de contrato...\")\n",
        "\n",
        "# Agrupar por tipo de contrato e calcular a receita total e a taxa de churn\n",
        "analise_contrato = df.groupby('Tipo_de_Contrato').agg(\n",
        "    Receita_Mensal_Total=('Cobrança_Mensal', 'sum'),\n",
        "    Numero_de_Clientes=('ID_Cliente', 'count'),\n",
        "    Taxa_de_Churn=('Churn', 'mean')\n",
        ").sort_values(by='Receita_Mensal_Total', ascending=False)\n",
        "\n",
        "analise_contrato['Taxa_de_Churn'] = analise_contrato['Taxa_de_Churn'] * 100\n",
        "\n",
        "print(\"\\n--- Análise Financeira por Tipo de Contrato ---\")\n",
        "display(analise_contrato.round(2))"
      ],
      "metadata": {
        "id": "tSsq1am7iZSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 17: Célula: Gerar Relatório HTML Consolidado\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Dependências para métricas e gráficos\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    roc_curve, classification_report\n",
        ")\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "\n",
        "# 1) KPIs básicos do dataset\n",
        "sections = []\n",
        "\n",
        "def safe_exists(var_name: str) -> bool:\n",
        "    return var_name in globals()\n",
        "\n",
        "now_str = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
        "project_dir = Path.cwd()\n",
        "report_path = project_dir / 'relatorio_churn.html'\n",
        "\n",
        "# Informações básicas\n",
        "try:\n",
        "    n_rows, n_cols = df.shape\n",
        "    churn_rate = float(df['Churn'].mean() * 100) if 'Churn' in df.columns else float('nan')\n",
        "    churn_counts = df['Churn'].value_counts().to_dict() if 'Churn' in df.columns else {}\n",
        "    kpis_html = f'''\n",
        "    <section>\n",
        "      <h2>Visão Geral</h2>\n",
        "      <ul>\n",
        "        <li>Linhas: <b>{n_rows:,}</b> • Colunas: <b>{n_cols}</b></li>\n",
        "        <li>Taxa de Churn: <b>{churn_rate:.2f}%</b></li>\n",
        "        <li>Distribuição Churn (0/1): <code>{json.dumps(churn_counts, ensure_ascii=False)}</code></li>\n",
        "        <li>Gerado em: {now_str}</li>\n",
        "      </ul>\n",
        "    </section>\n",
        "    '''\n",
        "    sections.append(kpis_html)\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao calcular KPIs:</b> {e}</p>\")\n",
        "\n",
        "# 2) Gráfico: Churn por Método de Pagamento (se houver)\n",
        "try:\n",
        "    if set(['Método_de_Pagamento','Churn']).issubset(df.columns):\n",
        "        churn_por_pagamento = df.groupby('Método_de_Pagamento')['Churn'].mean().sort_values(ascending=False) * 100\n",
        "        df_plot = churn_por_pagamento.reset_index().rename(columns={'Churn':'Taxa de Churn (%)'})\n",
        "        fig_pay = px.bar(\n",
        "            df_plot, x='Método_de_Pagamento', y='Taxa de Churn (%)',\n",
        "            title='Taxa de Churn por Método de Pagamento', text='Taxa de Churn (%)'\n",
        "        )\n",
        "        fig_pay.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
        "        fig_pay.update_layout(margin=dict(t=60,l=40,r=40,b=40))\n",
        "        div_pay = pio.to_html(fig_pay, include_plotlyjs='cdn', full_html=False, div_id='fig_pagamento')\n",
        "        sections.append('<section><h2>Churn por Método de Pagamento</h2>' + div_pay + '</section>')\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao gerar gráfico por pagamento:</b> {e}</p>\")\n",
        "\n",
        "# 3) Métricas de modelos e Curva ROC (se variáveis existirem)\n",
        "roc_fig = go.Figure()\n",
        "roc_any = False\n",
        "metrics_rows = []\n",
        "\n",
        "try:\n",
        "    # Garantir dados de teste escalados/originais quando necessário\n",
        "    have_test_scaled = safe_exists('X_test_scaled') and safe_exists('y_test')\n",
        "    have_test = safe_exists('X_test') and safe_exists('y_test')\n",
        "\n",
        "    # a) Regressão Logística (balanceada)\n",
        "    if safe_exists('modelo_log_bal') and have_test_scaled:\n",
        "        from numpy import ndarray\n",
        "        y_pred = modelo_log_bal.predict(X_test_scaled)\n",
        "        y_proba = getattr(modelo_log_bal, 'predict_proba')(X_test_scaled)[:,1]\n",
        "        metrics_rows.append({\n",
        "            'Modelo':'Reg. Logística (bal.)',\n",
        "            'Acurácia': accuracy_score(y_test, y_pred),\n",
        "            'Precisão': precision_score(y_test, y_pred, zero_division=0),\n",
        "            'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "            'F1': f1_score(y_test, y_pred, zero_division=0),\n",
        "            'AUC': roc_auc_score(y_test, y_proba)\n",
        "        })\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "        roc_fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='Reg. Logística'))\n",
        "        roc_any = True\n",
        "\n",
        "    # b) Random Forest (melhor via busca)\n",
        "    if safe_exists('best_rf_model') and have_test:\n",
        "        y_pred = best_rf_model.predict(X_test)\n",
        "        y_proba = best_rf_model.predict_proba(X_test)[:,1]\n",
        "        metrics_rows.append({\n",
        "            'Modelo':'Random Forest (best)',\n",
        "            'Acurácia': accuracy_score(y_test, y_pred),\n",
        "            'Precisão': precision_score(y_test, y_pred, zero_division=0),\n",
        "            'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "            'F1': f1_score(y_test, y_pred, zero_division=0),\n",
        "            'AUC': roc_auc_score(y_test, y_proba)\n",
        "        })\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "        roc_fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='Random Forest'))\n",
        "        roc_any = True\n",
        "\n",
        "    # c) XGBoost\n",
        "    if safe_exists('modelo_xgb') and have_test:\n",
        "        y_pred = modelo_xgb.predict(X_test)\n",
        "        # Garantir proba\n",
        "        y_proba = modelo_xgb.predict_proba(X_test)[:,1] if hasattr(modelo_xgb, 'predict_proba') else None\n",
        "        auc_val = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
        "        metrics_rows.append({\n",
        "            'Modelo':'XGBoost',\n",
        "            'Acurácia': accuracy_score(y_test, y_pred),\n",
        "            'Precisão': precision_score(y_test, y_pred, zero_division=0),\n",
        "            'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "            'F1': f1_score(y_test, y_pred, zero_division=0),\n",
        "            'AUC': auc_val\n",
        "        })\n",
        "        if y_proba is not None:\n",
        "            fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "            roc_fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='XGBoost'))\n",
        "            roc_any = True\n",
        "\n",
        "    # Montar tabela de métricas\n",
        "    if metrics_rows:\n",
        "        df_metrics = pd.DataFrame(metrics_rows)\n",
        "        df_metrics['Acurácia'] = (df_metrics['Acurácia']*100).round(2)\n",
        "        df_metrics['Precisão'] = (df_metrics['Precisão']*100).round(2)\n",
        "        df_metrics['Recall'] = (df_metrics['Recall']*100).round(2)\n",
        "        df_metrics['F1'] = (df_metrics['F1']*100).round(2)\n",
        "        if df_metrics['AUC'].notna().any():\n",
        "            df_metrics['AUC'] = df_metrics['AUC'].apply(lambda v: round(v,4) if pd.notna(v) else '')\n",
        "        table_html = df_metrics.to_html(index=False)\n",
        "        sections.append('<section><h2>Métricas de Modelos</h2>'+table_html+'</section>')\n",
        "\n",
        "    # Curva ROC\n",
        "    if roc_any:\n",
        "        roc_fig.update_layout(title='Curvas ROC', xaxis_title='FPR', yaxis_title='TPR',\n",
        "                              margin=dict(t=60,l=40,r=40,b=40))\n",
        "        roc_div = pio.to_html(roc_fig, include_plotlyjs='cdn', full_html=False, div_id='fig_roc')\n",
        "        sections.append('<section><h2>Curvas ROC</h2>'+roc_div+'</section>')\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao calcular métricas/ROC:</b> {e}</p>\")\n",
        "\n",
        "# 4) Top 10 clientes em maior risco (se disponível)\n",
        "try:\n",
        "    top_table_html = ''\n",
        "    if not safe_exists('df_resultados_ordenado') and safe_exists('best_rf_model') and safe_exists('X_test') and 'ID_Cliente' in df.columns:\n",
        "        # Recalcular rapidamente a tabela de resultados se necessário\n",
        "        probs = best_rf_model.predict_proba(X_test)[:,1]\n",
        "        df_resultados = df.loc[X_test.index].copy()\n",
        "        df_resultados['Probabilidade_Churn'] = probs\n",
        "        df_resultados_ordenado = df_resultados.sort_values(by='Probabilidade_Churn', ascending=False)\n",
        "    if safe_exists('df_resultados_ordenado'):\n",
        "        cols = [c for c in ['ID_Cliente','Probabilidade_Churn','Tempo_de_Contrato_Meses','Tipo_de_Contrato','Cobrança_Mensal','Cobrança_Total'] if c in df_resultados_ordenado.columns]\n",
        "        top_table_html = df_resultados_ordenado[cols].head(10).to_html(index=False)\n",
        "        sections.append('<section><h2>Top 10 Clientes com Maior Risco</h2>'+top_table_html+'</section>')\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao gerar Top 10:</b> {e}</p>\")\n",
        "\n",
        "# 5) Montagem final do HTML\n",
        "html = f'''\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-br\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\" />\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
        "  <title>Relatório de Churn</title>\n",
        "  <style>\n",
        "    body {{ font-family: Arial, sans-serif; margin: 24px; }}\n",
        "    h1 {{ margin-bottom: 0; }}\n",
        "    h2 {{ margin-top: 32px; }}\n",
        "    section {{ margin-bottom: 24px; }}\n",
        "    table {{ border-collapse: collapse; width: 100%; }}\n",
        "    table, th, td {{ border: 1px solid #ddd; }}\n",
        "    th, td {{ padding: 8px; text-align: left; }}\n",
        "    th {{ background: #f5f5f5; }}\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Relatório de Churn</h1>\n",
        "  <p><small>Gerado em {now_str}</small></p>\n",
        "  {''.join(sections)}\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "# 6) Salvar arquivo\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(html)\n",
        "\n",
        "print(f\"Relatório salvo em: {report_path}\")"
      ],
      "metadata": {
        "id": "4bVxd3p5ifZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 17\n",
        "\n",
        "# Célula: Seleção de Modelo e Probabilidades para Previsão\n",
        "import numpy as np\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "print(\"Preparando o modelo e as probabilidades para análises preditivas...\")\n",
        "\n",
        "best_model = None\n",
        "X_eval = None\n",
        "use_scaled = False\n",
        "\n",
        "# Seleção de modelo com base no que está disponível no kernel\n",
        "if 'best_rf_model' in globals():\n",
        "    best_model = best_rf_model\n",
        "    X_eval = X_test if 'X_test' in globals() else None\n",
        "    use_scaled = False\n",
        "    print(\"Modelo selecionado: Random Forest (best)\")\n",
        "elif 'modelo_xgb' in globals():\n",
        "    best_model = modelo_xgb\n",
        "    X_eval = X_test if 'X_test' in globals() else None\n",
        "    use_scaled = False\n",
        "    print(\"Modelo selecionado: XGBoost\")\n",
        "elif 'modelo_log_bal' in globals():\n",
        "    best_model = modelo_log_bal\n",
        "    X_eval = X_test_scaled if 'X_test_scaled' in globals() else None\n",
        "    use_scaled = True\n",
        "    print(\"Modelo selecionado: Regressão Logística (balanceada)\")\n",
        "else:\n",
        "    print(\"Nenhum modelo encontrado. Execute as células de treinamento antes desta.\")\n",
        "\n",
        "if best_model is not None and 'y_test' in globals() and X_eval is not None:\n",
        "    if hasattr(best_model, 'predict_proba'):\n",
        "        y_proba = best_model.predict_proba(X_eval)[:, 1]\n",
        "    else:\n",
        "        # fallback para decisões como pontuações; normaliza para [0,1]\n",
        "        scores = best_model.decision_function(X_eval)\n",
        "        y_proba = (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)\n",
        "    print(\"Probabilidades calculadas com sucesso.\")\n",
        "else:\n",
        "    y_proba = None\n",
        "    print(\"Impossível calcular probabilidades: verifique X_test/X_test_scaled e y_test.\")\n"
      ],
      "metadata": {
        "id": "jFm9Q3wyingQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celula 18: Célula: Curvas ROC / Precision-Recall e Threshold Ótimo (F1)\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc, f1_score\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "if 'y_test' in globals() and 'y_proba' in globals() and y_proba is not None:\n",
        "    # ROC\n",
        "    fpr, tpr, thr_roc = roc_curve(y_test, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # PR\n",
        "    precision, recall, thr_pr = precision_recall_curve(y_test, y_proba)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    # Threshold ótimo por F1 (varrendo thresholds de 0.01 em 0.99)\n",
        "    thresholds = np.linspace(0.01, 0.99, 99)\n",
        "    f1s = []\n",
        "    for t in thresholds:\n",
        "        y_hat = (y_proba >= t).astype(int)\n",
        "        f1s.append(f1_score(y_test, y_hat, zero_division=0))\n",
        "    best_idx = int(np.argmax(f1s))\n",
        "    best_threshold = float(thresholds[best_idx])\n",
        "    best_f1 = float(f1s[best_idx])\n",
        "\n",
        "    # Plot ROC\n",
        "    fig_roc = go.Figure()\n",
        "    fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC={roc_auc:.3f})'))\n",
        "    fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Aleatório', line=dict(dash='dash')))\n",
        "    fig_roc.update_layout(title='Curva ROC', xaxis_title='FPR', yaxis_title='TPR')\n",
        "    fig_roc.show()\n",
        "\n",
        "    # Plot Precision-Recall + F1\n",
        "    fig_pr = go.Figure()\n",
        "    fig_pr.add_trace(go.Scatter(x=recall, y=precision, mode='lines', name=f'PR (AUC={pr_auc:.3f})'))\n",
        "    fig_pr.update_layout(title='Curva Precision-Recall', xaxis_title='Recall', yaxis_title='Precisão')\n",
        "    fig_pr.show()\n",
        "\n",
        "    fig_f1 = go.Figure()\n",
        "    fig_f1.add_trace(go.Scatter(x=thresholds, y=f1s, mode='lines+markers', name='F1 vs Threshold'))\n",
        "    fig_f1.add_trace(go.Scatter(x=[best_threshold], y=[best_f1], mode='markers', marker=dict(size=10, color='red'), name='Melhor F1'))\n",
        "    fig_f1.update_layout(title='Seleção de Threshold por F1', xaxis_title='Threshold', yaxis_title='F1')\n",
        "    fig_f1.show()\n",
        "\n",
        "    print(f\"Threshold ótimo (F1): {best_threshold:.3f} | F1: {best_f1:.3f} | ROC AUC: {roc_auc:.3f} | PR AUC: {pr_auc:.3f}\")\n",
        "else:\n",
        "    best_threshold = None\n",
        "    print(\"Probabilidades ou y_test indisponíveis. Execute as células anteriores.\")\n"
      ],
      "metadata": {
        "id": "NMTEUPNwi2wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 19: Célula: Matriz de Confusão e Métricas no Threshold Ótimo\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "if 'y_test' in globals() and 'y_proba' in globals() and y_proba is not None and 'best_threshold' in globals() and best_threshold is not None:\n",
        "    y_pred_thr = (y_proba >= best_threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred_thr)\n",
        "    prec = precision_score(y_test, y_pred_thr, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred_thr, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred_thr, zero_division=0)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_thr)\n",
        "    cm_df = pd.DataFrame(cm, index=['Real 0','Real 1'], columns=['Pred 0','Pred 1'])\n",
        "    print(\"Matriz de Confusão:\")\n",
        "    display(cm_df)\n",
        "\n",
        "    print(f\"\\nAcurácia: {acc:.3f} | Precisão: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f}\")\n",
        "\n",
        "    fig_cm = px.imshow(cm_df, text_auto=True, color_continuous_scale='Blues', title='Matriz de Confusão')\n",
        "    fig_cm.update_layout(margin=dict(t=60,l=40,r=40,b=40))\n",
        "    fig_cm.show()\n",
        "else:\n",
        "    print(\"Não foi possível calcular a matriz de confusão. Verifique as células anteriores.\")\n"
      ],
      "metadata": {
        "id": "yv5Wk7Zmi_FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 20: Célula: Importância de Features (Top 20)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "if 'best_model' in globals() and best_model is not None:\n",
        "    feature_names = list(X_encoded.columns) if 'X_encoded' in globals() else None\n",
        "    importances = None\n",
        "\n",
        "    if hasattr(best_model, 'feature_importances_') and feature_names is not None:\n",
        "        importances = best_model.feature_importances_\n",
        "        title = 'Importâncias de Features (modelo árvore)'\n",
        "    else:\n",
        "        # Tentar permutation_importance se possível e se tivermos X_eval/y_test\n",
        "        try:\n",
        "            from sklearn.inspection import permutation_importance\n",
        "            if 'X_test' in globals() and 'y_test' in globals() and feature_names is not None:\n",
        "                result = permutation_importance(best_model, X_test, y_test, n_repeats=5, random_state=42, n_jobs=-1)\n",
        "                importances = result.importances_mean\n",
        "                title = 'Importâncias por Permutação'\n",
        "        except Exception as e:\n",
        "            print('Falha ao calcular importâncias por permutação:', e)\n",
        "\n",
        "    if importances is not None and feature_names is not None:\n",
        "        imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "        imp_top = imp_df.sort_values('importance', ascending=False).head(20)\n",
        "        fig_imp = px.bar(imp_top.sort_values('importance'), x='importance', y='feature', orientation='h', title=title)\n",
        "        fig_imp.update_layout(margin=dict(t=60,l=40,r=40,b=40))\n",
        "        fig_imp.show()\n",
        "    else:\n",
        "        print('Não foi possível obter importâncias de features com o modelo atual.')\n",
        "else:\n",
        "    print('Nenhum modelo disponível para calcular importâncias.')\n"
      ],
      "metadata": {
        "id": "cC0ulu0ujHWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 21: Salvar Artefatos do Modelo para Produção\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "artefatos_dir = Path.cwd() / 'artefatos_modelo'\n",
        "artefatos_dir.mkdir(exist_ok=True)\n",
        "\n",
        "meta = {\n",
        "    'gerado_em': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'modelo': type(best_model).__name__ if 'best_model' in globals() and best_model is not None else None,\n",
        "    'threshold': float(best_threshold) if 'best_threshold' in globals() and best_threshold is not None else None,\n",
        "    'use_scaled': bool(use_scaled) if 'use_scaled' in globals() else False,\n",
        "}\n",
        "\n",
        "if 'best_model' in globals() and best_model is not None:\n",
        "    joblib.dump(best_model, artefatos_dir / 'modelo.joblib')\n",
        "    print('Modelo salvo em', artefatos_dir / 'modelo.joblib')\n",
        "\n",
        "if 'scaler' in globals():\n",
        "    joblib.dump(scaler, artefatos_dir / 'scaler.joblib')\n",
        "    print('Scaler salvo em', artefatos_dir / 'scaler.joblib')\n",
        "\n",
        "if 'X_encoded' in globals():\n",
        "    joblib.dump(list(X_encoded.columns), artefatos_dir / 'colunas_X_encoded.joblib')\n",
        "    print('Colunas de X_encoded salvas em', artefatos_dir / 'colunas_X_encoded.joblib')\n",
        "\n",
        "joblib.dump(meta, artefatos_dir / 'metadata.joblib')\n",
        "print('Metadata salva em', artefatos_dir / 'metadata.joblib')\n"
      ],
      "metadata": {
        "id": "znEmJBJTjPtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 22: Calibração de Probabilidades (CalibratedClassifierCV)\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.base import clone\n",
        "from sklearn.metrics import brier_score_loss\n",
        "import numpy as np\n",
        "\n",
        "if 'best_model' in globals() and best_model is not None and 'y_test' in globals():\n",
        "    # Selecionar matrizes corretas (escaladas ou não)\n",
        "    X_train_eval = X_train_scaled if ('X_train_scaled' in globals() and use_scaled) else X_train\n",
        "    X_test_eval  = X_test_scaled  if ('X_test_scaled' in globals() and use_scaled) else X_test\n",
        "\n",
        "    if X_train_eval is None or X_test_eval is None:\n",
        "        print('Dados de treino/teste não encontrados para calibração.')\n",
        "    else:\n",
        "        print('Iniciando calibração (sigmoid, cv=3)...')\n",
        "        base = clone(best_model)\n",
        "        calibrator = CalibratedClassifierCV(estimator=base, cv=3, method='sigmoid')\n",
        "        calibrator.fit(X_train_eval, y_train)\n",
        "\n",
        "        # Probabilidades originais vs calibradas\n",
        "        y_proba_orig = y_proba if 'y_proba' in globals() and y_proba is not None else (\n",
        "            best_model.predict_proba(X_test_eval)[:,1] if hasattr(best_model,'predict_proba') else None\n",
        "        )\n",
        "        y_proba_cal = calibrator.predict_proba(X_test_eval)[:,1]\n",
        "\n",
        "        # Brier score: menor é melhor\n",
        "        brier_orig = brier_score_loss(y_test, y_proba_orig) if y_proba_orig is not None else np.inf\n",
        "        brier_cal  = brier_score_loss(y_test, y_proba_cal)\n",
        "        print(f'Brier (orig): {brier_orig:.4f} | Brier (cal): {brier_cal:.4f}')\n",
        "\n",
        "        # Threshold ótimo por F1 com probabilidades calibradas\n",
        "        thresholds = np.linspace(0.01, 0.99, 99)\n",
        "        f1s = []\n",
        "        for t in thresholds:\n",
        "            y_hat = (y_proba_cal >= t).astype(int)\n",
        "            f1s.append(f1_score(y_test, y_hat, zero_division=0))\n",
        "        best_idx = int(np.argmax(f1s))\n",
        "        best_threshold_cal = float(thresholds[best_idx])\n",
        "        best_f1_cal = float(f1s[best_idx])\n",
        "        print(f'Threshold ótimo (calibrado) = {best_threshold_cal:.3f} | F1 (cal) = {best_f1_cal:.3f}')\n",
        "\n",
        "        # Adotar calibrado se Brier melhorar\n",
        "        if brier_cal < brier_orig:\n",
        "            print('Adotando modelo calibrado para etapas seguintes.')\n",
        "            best_model = calibrator\n",
        "            y_proba = y_proba_cal\n",
        "            best_threshold = best_threshold_cal\n",
        "        else:\n",
        "            print('Mantendo probabilidades originais (calibração não melhorou Brier).')\n",
        "else:\n",
        "    print('Modelo ou y_test indisponíveis; execute as células anteriores.')\n"
      ],
      "metadata": {
        "id": "sRf5bk7pjUqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 23: Funções de Inferência (carrega artefatos e prevê para um registro)\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "ARTEFATOS_DIR = Path.cwd() / 'artefatos_modelo'\n",
        "\n",
        "def carregar_artefatos():\n",
        "    modelo_path = ARTEFATOS_DIR / 'modelo.joblib'\n",
        "    scaler_path = ARTEFATOS_DIR / 'scaler.joblib'\n",
        "    cols_path   = ARTEFATOS_DIR / 'colunas_X_encoded.joblib'\n",
        "    meta_path   = ARTEFATOS_DIR / 'metadata.joblib'\n",
        "\n",
        "    modelo = joblib.load(modelo_path) if modelo_path.exists() else (best_model if 'best_model' in globals() else None)\n",
        "    scaler = joblib.load(scaler_path) if scaler_path.exists() else (scaler if 'scaler' in globals() else None)\n",
        "    colunas = joblib.load(cols_path) if cols_path.exists() else (list(X_encoded.columns) if 'X_encoded' in globals() else None)\n",
        "    meta = joblib.load(meta_path) if meta_path.exists() else {'threshold': best_threshold if 'best_threshold' in globals() else 0.5, 'use_scaled': bool(use_scaled) if 'use_scaled' in globals() else False}\n",
        "    return modelo, scaler, colunas, meta\n",
        "\n",
        "\n",
        "def preparar_features(registro: dict, colunas_fit: list) -> pd.DataFrame:\n",
        "    df_input = pd.DataFrame([registro])\n",
        "    X_enc = pd.get_dummies(df_input, drop_first=True)\n",
        "    X_enc = X_enc.reindex(columns=colunas_fit, fill_value=0)\n",
        "    return X_enc\n",
        "\n",
        "\n",
        "def prever_churn(registro: dict):\n",
        "    modelo, scaler_obj, colunas_fit, meta = carregar_artefatos()\n",
        "    if modelo is None or colunas_fit is None:\n",
        "        raise RuntimeError('Artefatos insuficientes para inferência. Treine/salve o modelo primeiro.')\n",
        "    X_enc = preparar_features(registro, colunas_fit)\n",
        "    # Aplicar scaler apenas se o pipeline do modelo exigir\n",
        "    if meta.get('use_scaled', False) and scaler_obj is not None:\n",
        "        X_eval = scaler_obj.transform(X_enc)\n",
        "    else:\n",
        "        X_eval = X_enc\n",
        "    proba = modelo.predict_proba(X_eval)[:,1] if hasattr(modelo,'predict_proba') else modelo.predict(X_eval)\n",
        "    thr = float(meta.get('threshold', 0.5))\n",
        "    pred = (proba >= thr).astype(int)\n",
        "    return float(proba[0]), int(pred[0]), thr\n",
        "\n",
        "# Exemplo de uso (utilizando o primeiro registro de df, excluindo colunas alvo/ID)\n",
        "try:\n",
        "    exemplo = df.drop(columns=[c for c in ['Churn','ID_Cliente'] if c in df.columns]).iloc[0].to_dict()\n",
        "    p, yhat, thr = prever_churn(exemplo)\n",
        "    print(f\"Exemplo -> Prob: {p:.3f} | Classe (thr={thr:.3f}): {yhat}\")\n",
        "except Exception as e:\n",
        "    print('Não foi possível executar exemplo de inferência:', e)\n"
      ],
      "metadata": {
        "id": "prZ2jkn9jawR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 24: Atualizar Relatório HTML com Análises Preditivas\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    roc_curve, precision_recall_curve, auc, confusion_matrix\n",
        ")\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "\n",
        "sections = []\n",
        "now_str = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
        "project_dir = Path.cwd()\n",
        "report_path = project_dir / 'relatorio_churn.html'\n",
        "\n",
        "# 1) KPIs básicos\n",
        "try:\n",
        "    n_rows, n_cols = df.shape\n",
        "    churn_rate = float(df['Churn'].mean() * 100) if 'Churn' in df.columns else float('nan')\n",
        "    churn_counts = df['Churn'].value_counts().to_dict() if 'Churn' in df.columns else {}\n",
        "    kpis_html = f'''\n",
        "    <section>\n",
        "      <h2>Visão Geral</h2>\n",
        "      <ul>\n",
        "        <li>Linhas: <b>{n_rows:,}</b> • Colunas: <b>{n_cols}</b></li>\n",
        "        <li>Taxa de Churn: <b>{churn_rate:.2f}%</b></li>\n",
        "        <li>Distribuição Churn (0/1): <code>{json.dumps(churn_counts, ensure_ascii=False)}</code></li>\n",
        "        <li>Gerado em: {now_str}</li>\n",
        "      </ul>\n",
        "    </section>\n",
        "    '''\n",
        "    sections.append(kpis_html)\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao calcular KPIs:</b> {e}</p>\")\n",
        "\n",
        "# 2) Churn por Método de Pagamento\n",
        "try:\n",
        "    if set(['Método_de_Pagamento','Churn']).issubset(df.columns):\n",
        "        churn_por_pagamento = df.groupby('Método_de_Pagamento')['Churn'].mean().sort_values(ascending=False) * 100\n",
        "        df_plot = churn_por_pagamento.reset_index().rename(columns={'Churn':'Taxa de Churn (%)'})\n",
        "        fig_pay = px.bar(df_plot, x='Método_de_Pagamento', y='Taxa de Churn (%)', title='Taxa de Churn por Método de Pagamento', text='Taxa de Churn (%)')\n",
        "        fig_pay.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
        "        fig_pay.update_layout(margin=dict(t=60,l=40,r=40,b=40))\n",
        "        div_pay = pio.to_html(fig_pay, include_plotlyjs='cdn', full_html=False, div_id='fig_pagamento')\n",
        "        sections.append('<section><h2>Churn por Método de Pagamento</h2>' + div_pay + '</section>')\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao gerar gráfico por pagamento:</b> {e}</p>\")\n",
        "\n",
        "# 3) Métricas + Curvas (se disponíveis)\n",
        "try:\n",
        "    if 'y_test' in globals() and 'y_proba' in globals() and y_proba is not None:\n",
        "        # ROC/PR\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
        "        pr_auc = auc(recall, precision)\n",
        "\n",
        "        fig_roc = go.Figure()\n",
        "        fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC={roc_auc:.3f})'))\n",
        "        fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Aleatório', line=dict(dash='dash')))\n",
        "        fig_roc.update_layout(title='Curva ROC', xaxis_title='FPR', yaxis_title='TPR', margin=dict(t=60,l=40,r=40,b=40))\n",
        "        roc_div = pio.to_html(fig_roc, include_plotlyjs='cdn', full_html=False, div_id='fig_roc_html')\n",
        "\n",
        "        fig_pr = go.Figure()\n",
        "        fig_pr.add_trace(go.Scatter(x=recall, y=precision, mode='lines', name=f'PR (AUC={pr_auc:.3f})'))\n",
        "        fig_pr.update_layout(title='Curva Precision-Recall', xaxis_title='Recall', yaxis_title='Precisão', margin=dict(t=60,l=40,r=40,b=40))\n",
        "        pr_div = pio.to_html(fig_pr, include_plotlyjs=False, full_html=False, div_id='fig_pr_html')\n",
        "\n",
        "        # Threshold e matriz de confusão\n",
        "        thr = float(best_threshold) if 'best_threshold' in globals() and best_threshold is not None else 0.5\n",
        "        y_pred_thr = (y_proba >= thr).astype(int)\n",
        "        cm = confusion_matrix(y_test, y_pred_thr)\n",
        "        acc = accuracy_score(y_test, y_pred_thr)\n",
        "        prec = precision_score(y_test, y_pred_thr, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred_thr, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred_thr, zero_division=0)\n",
        "        cm_df = pd.DataFrame(cm, index=['Real 0','Real 1'], columns=['Pred 0','Pred 1'])\n",
        "        cm_table = cm_df.to_html()\n",
        "\n",
        "        metrics_html = f'''\n",
        "        <section>\n",
        "          <h2>Métricas de Classificação (threshold={thr:.3f})</h2>\n",
        "          <ul>\n",
        "            <li>Acurácia: <b>{acc:.3f}</b></li>\n",
        "            <li>Precisão: <b>{prec:.3f}</b></li>\n",
        "            <li>Recall: <b>{rec:.3f}</b></li>\n",
        "            <li>F1: <b>{f1:.3f}</b></li>\n",
        "            <li>ROC AUC: <b>{roc_auc:.3f}</b> • PR AUC: <b>{pr_auc:.3f}</b></li>\n",
        "          </ul>\n",
        "          <h3>Matriz de Confusão</h3>\n",
        "          {cm_table}\n",
        "          <h3>Curvas</h3>\n",
        "          {roc_div}\n",
        "          {pr_div}\n",
        "        </section>\n",
        "        '''\n",
        "        sections.append(metrics_html)\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao gerar métricas/curvas:</b> {e}</p>\")\n",
        "\n",
        "# 4) Top 10 clientes em risco (se disponível)\n",
        "try:\n",
        "    if 'df_resultados_ordenado' in globals():\n",
        "        cols = [c for c in ['ID_Cliente','Probabilidade_Churn','Tempo_de_Contrato_Meses','Tipo_de_Contrato','Cobrança_Mensal','Cobrança_Total'] if c in df_resultados_ordenado.columns]\n",
        "        top_table_html = df_resultados_ordenado[cols].head(10).to_html(index=False)\n",
        "        sections.append('<section><h2>Top 10 Clientes com Maior Risco</h2>'+top_table_html+'</section>')\n",
        "except Exception as e:\n",
        "    sections.append(f\"<p><b>Falha ao gerar Top 10:</b> {e}</p>\")\n",
        "\n",
        "# 5) Montagem final e salvar\n",
        "html = f'''\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-br\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\" />\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
        "  <title>Relatório de Churn</title>\n",
        "  <style>\n",
        "    body {{ font-family: Arial, sans-serif; margin: 24px; }}\n",
        "    h1 {{ margin-bottom: 0; }}\n",
        "    h2 {{ margin-top: 32px; }}\n",
        "    section {{ margin-bottom: 24px; }}\n",
        "    table {{ border-collapse: collapse; width: 100%; }}\n",
        "    table, th, td {{ border: 1px solid #ddd; }}\n",
        "    th, td {{ padding: 8px; text-align: left; }}\n",
        "    th {{ background: #f5f5f5; }}\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Relatório de Churn</h1>\n",
        "  <p><small>Gerado em {now_str}</small></p>\n",
        "  {''.join(sections)}\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(html)\n",
        "\n",
        "print(f'Relatório atualizado salvo em: {report_path}')\n"
      ],
      "metadata": {
        "id": "D5a4rJ-sjdQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 25: Curva de Calibração (Reliability Diagram) e Brier Score\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import brier_score_loss\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "if 'y_test' in globals() and 'y_proba' in globals() and y_proba is not None:\n",
        "    frac_pos, mean_pred = calibration_curve(y_test, y_proba, n_bins=10, strategy='quantile')\n",
        "    brier = brier_score_loss(y_test, y_proba)\n",
        "\n",
        "    fig_cal = go.Figure()\n",
        "    fig_cal.add_trace(go.Scatter(x=mean_pred, y=frac_pos, mode='lines+markers', name='Calibração'))\n",
        "    fig_cal.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Perfeita', line=dict(dash='dash')))\n",
        "    fig_cal.update_layout(title=f'Curva de Calibração (Brier={brier:.3f})', xaxis_title='Probabilidade prevista', yaxis_title='Frequência observada')\n",
        "    fig_cal.show()\n",
        "    print(f\"Brier Score: {brier:.4f}\")\n",
        "else:\n",
        "    print('Probabilidades/y_test indisponíveis. Execute as células anteriores.')\n"
      ],
      "metadata": {
        "id": "GRGGHFRhjoA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 26: Threshold Ótimo por Custo (defina seus custos/benefícios)\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Ajuste estes valores para sua realidade de negócio\n",
        "custo_fp = 10.0   # custo de abordar um cliente que não sairia\n",
        "custo_fn = 200.0  # custo de perder um cliente que sairia (perda de receita)\n",
        "beneficio_tp = 150.0  # benefício ao reter com sucesso um cliente que sairia\n",
        "\n",
        "if 'y_test' in globals() and 'y_proba' in globals() and y_proba is not None:\n",
        "    thresholds = np.linspace(0.01, 0.99, 99)\n",
        "    custos = []\n",
        "\n",
        "    for t in thresholds:\n",
        "        y_hat = (y_proba >= t).astype(int)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
        "        # Custo esperado: penaliza FP/FN e subtrai benefício dos TP\n",
        "        custo = (fp * custo_fp) + (fn * custo_fn) - (tp * beneficio_tp)\n",
        "        custos.append(custo)\n",
        "\n",
        "    i_best = int(np.argmin(custos))\n",
        "    t_best = float(thresholds[i_best])\n",
        "    custo_best = float(custos[i_best])\n",
        "    print(f\"Threshold ótimo por custo: {t_best:.3f} | Custo esperado: {custo_best:.2f}\")\n",
        "    # manter disponível para outras células\n",
        "    threshold_custo = t_best\n",
        "else:\n",
        "    print('Probabilidades/y_test indisponíveis. Execute as células anteriores.')\n"
      ],
      "metadata": {
        "id": "TvrmZchKjtxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 27 (renomeada para melhor clareza): SHAP - Explicabilidade do Modelo (Top 20 Features)\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Escolher um modelo de árvore para SHAP (prioriza XGBoost, depois RandomForest)\n",
        "shap_model = None\n",
        "shap_X = None\n",
        "feature_names = list(X_encoded.columns) if 'X_encoded' in globals() else None\n",
        "\n",
        "if 'modelo_xgb' in globals():\n",
        "    shap_model = modelo_xgb\n",
        "    shap_X = X_test if 'X_test' in globals() else None\n",
        "elif 'best_rf_model' in globals():\n",
        "    shap_model = best_rf_model\n",
        "    shap_X = X_test if 'X_test' in globals() else None\n",
        "else:\n",
        "    # fallback: tentar usar best_model se for árvore\n",
        "    shap_model = best_model if 'best_model' in globals() else None\n",
        "    shap_X = X_test if 'X_test' in globals() else None\n",
        "\n",
        "if shap_model is not None and shap_X is not None and feature_names is not None:\n",
        "    try:\n",
        "        # Para modelos de árvore, TreeExplainer é rápido\n",
        "        explainer = shap.TreeExplainer(shap_model)\n",
        "        # Amostra para agilizar\n",
        "        X_sample = X_test.iloc[idx].astype(float) # Adicione .astype(float)\n",
        "        shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "        # A conversão para DataFrame garante que tenhamos os nomes das colunas corretos\n",
        "        X_sample_df = pd.DataFrame(X_test, columns=feature_names)\n",
        "        X_sample = X_sample_df.sample(n=min(500, X_test.shape[0]), random_state=42)\n",
        "\n",
        "        # --- CORREÇÃO APLICADA AQUI ---\n",
        "        # Convertendo explicitamente os dados para o tipo float para evitar o ValueError\n",
        "        shap_values = explainer.shap_values(X_sample.astype(float))\n",
        "\n",
        "        # SHAP pode retornar lista (para multiclass); em binário usamos o componente 1 se aplicável\n",
        "        if isinstance(shap_values, list) and len(shap_values) > 1:\n",
        "            shap_vals = shap_values[1]\n",
        "        else:\n",
        "            shap_vals = shap_values\n",
        "\n",
        "        # Importância média absoluta\n",
        "        mean_abs = np.abs(shap_vals).mean(axis=0)\n",
        "        imp_df = pd.DataFrame({'feature': feature_names, 'importance': mean_abs})\n",
        "        imp_top = imp_df.sort_values('importance', ascending=False).head(20)\n",
        "\n",
        "        fig_shap = px.bar(\n",
        "            imp_top.sort_values('importance'),\n",
        "            x='importance',\n",
        "            y='feature',\n",
        "            orientation='h',\n",
        "            title='SHAP Importância de Features (Top 20)'\n",
        "        )\n",
        "        fig_shap.update_layout(margin=dict(t=60, l=40, r=40, b=40))\n",
        "        fig_shap.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Não foi possível calcular SHAP para o modelo atual: {e}')\n",
        "else:\n",
        "    print('Modelo/dados indisponíveis para SHAP. Execute as células de treino e split antes.')"
      ],
      "metadata": {
        "id": "GXYiUDOcj0CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 28: Atualização do relatório HTML com calibração, custo e SHAP\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io, base64, datetime, json, sys\n",
        "from sklearn.metrics import (\n",
        "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score,\n",
        "    confusion_matrix, f1_score, brier_score_loss\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.calibration import calibration_curve\n",
        "import joblib\n",
        "\n",
        "# Algumas dependências podem ser opcionais\n",
        "try:\n",
        "    import shap\n",
        "except Exception:\n",
        "    shap = None\n",
        "\n",
        "# Utilidades\n",
        "plt.rcParams.update({\"figure.facecolor\": \"white\"})\n",
        "\n",
        "def fig_to_base64(fig):\n",
        "    buf = io.BytesIO()\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(buf, format=\"png\", dpi=120, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    return base64.b64encode(buf.getvalue()).decode()\n",
        "\n",
        "base_dir = Path.cwd()  # Notebook está em DataSet\n",
        "csv_path = base_dir / \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "artef_dir = base_dir / \"artefatos_modelo\"\n",
        "report_path = base_dir / \"relatorio_churn.html\"\n",
        "\n",
        "# Carregar dados com mínimos ajustes compatíveis com os artefatos\n",
        "\n",
        "def carregar_dados_telco(caminho_csv: Path):\n",
        "    df = pd.read_csv(caminho_csv)\n",
        "    # Limpeza mínima\n",
        "    if 'TotalCharges' in df.columns:\n",
        "        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "        df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
        "    # Alvo\n",
        "    y = df['Churn'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0}).astype(int)\n",
        "    id_col = 'customerID' if 'customerID' in df.columns else None\n",
        "    X = df.drop(columns=[c for c in ['Churn', 'customerID'] if c in df.columns])\n",
        "    X_enc = pd.get_dummies(X, drop_first=True)\n",
        "    return df, X_enc, y, id_col\n",
        "\n",
        "\n",
        "def alinhar_colunas(X_enc: pd.DataFrame, colunas_artef):\n",
        "    X2 = X_enc.copy()\n",
        "    for c in colunas_artef:\n",
        "        if c not in X2.columns:\n",
        "            X2[c] = 0\n",
        "    # remover extras não vistos pelo modelo\n",
        "    X2 = X2[colunas_artef]\n",
        "    return X2\n",
        "\n",
        "# Carrega artefatos salvos\n",
        "modelo = joblib.load(artef_dir / \"modelo.joblib\")\n",
        "metadata = joblib.load(artef_dir / \"metadata.joblib\") if (artef_dir / \"metadata.joblib\").exists() else {}\n",
        "colunas = joblib.load(artef_dir / \"colunas_X_encoded.joblib\")\n",
        "scaler = joblib.load(artef_dir / \"scaler.joblib\") if (artef_dir / \"scaler.joblib\").exists() else None\n",
        "\n",
        "use_scaled = metadata.get('use_scaled', False)\n",
        "thr_meta = float(metadata.get('threshold', 0.5))\n",
        "\n",
        "# Monta conjunto de teste reprodutível (aproximação do split original)\n",
        "df_raw, X_enc, y, id_col = carregar_dados_telco(csv_path)\n",
        "X_enc = alinhar_colunas(X_enc, colunas)\n",
        "indices = np.arange(len(X_enc))\n",
        "X_tr, X_te, y_tr, y_te, idx_tr, idx_te = train_test_split(\n",
        "    X_enc, y.values, indices, test_size=0.2, random_state=42, stratify=y.values\n",
        ")\n",
        "\n",
        "# Aplica scaler se necessário\n",
        "X_te_infer = X_te\n",
        "if use_scaled and scaler is not None:\n",
        "    X_te_infer = scaler.transform(X_te)\n",
        "\n",
        "# Probabilidades\n",
        "if hasattr(modelo, 'predict_proba'):\n",
        "    y_proba = modelo.predict_proba(X_te_infer)[:, 1]\n",
        "elif hasattr(modelo, 'decision_function'):\n",
        "    s = modelo.decision_function(X_te_infer)\n",
        "    # normalização simples para [0,1] caso falte calibrador\n",
        "    y_proba = (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
        "else:\n",
        "    # fallback: usar previsões como probas binárias\n",
        "    y_proba = modelo.predict(X_te_infer).astype(float)\n",
        "\n",
        "# Métricas principais\n",
        "roc_auc = roc_auc_score(y_te, y_proba)\n",
        "prec, rec, thr_pr = precision_recall_curve(y_te, y_proba)\n",
        "pr_auc = average_precision_score(y_te, y_proba)\n",
        "\n",
        "# Threshold ótimo por F1\n",
        "cand_thr = np.r_[0.0, thr_pr, 1.0]\n",
        "best_f1, best_thr = -1.0, thr_meta\n",
        "for t in cand_thr:\n",
        "    y_hat = (y_proba >= t).astype(int)\n",
        "    f1 = f1_score(y_te, y_hat)\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_thr = f1, float(t)\n",
        "\n",
        "# Matriz de confusão no threshold F1-ótimo\n",
        "cm = confusion_matrix(y_te, (y_proba >= best_thr).astype(int))\n",
        "\n",
        "# Curva ROC\n",
        "fpr, tpr, _ = roc_curve(y_te, y_proba)\n",
        "fig_roc = plt.figure(figsize=(5,4))\n",
        "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n",
        "plt.plot([0,1],[0,1],'--', color='gray')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend()\n",
        "roc_img64 = fig_to_base64(fig_roc)\n",
        "\n",
        "# Curva Precisão-Recall\n",
        "fig_pr = plt.figure(figsize=(5,4))\n",
        "plt.plot(rec, prec, label=f\"PR AUC = {pr_auc:.3f}\")\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precisão')\n",
        "plt.title('Curva Precisão-Recall')\n",
        "plt.legend()\n",
        "pr_img64 = fig_to_base64(fig_pr)\n",
        "\n",
        "# Curva de calibração e Brier\n",
        "prob_true, prob_pred = calibration_curve(y_te, y_proba, n_bins=10, strategy='uniform')\n",
        "brier = brier_score_loss(y_te, y_proba)\n",
        "fig_cal = plt.figure(figsize=(5,4))\n",
        "plt.plot(prob_pred, prob_true, marker='o', label=f\"Calibração (Brier={brier:.3f})\")\n",
        "plt.plot([0,1],[0,1],'--', color='gray', label='Perfeita')\n",
        "plt.xlabel('Prob. prevista')\n",
        "plt.ylabel('Frequência observada')\n",
        "plt.title('Curva de Calibração')\n",
        "plt.legend()\n",
        "cal_img64 = fig_to_base64(fig_cal)\n",
        "\n",
        "# Threshold ótimo por custo esperado (ex.: FN=10x FP)\n",
        "C_FN, C_FP = 10.0, 1.0\n",
        "cost_best, thr_cost = float('inf'), best_thr\n",
        "for t in np.linspace(0, 1, 201):\n",
        "    y_hat = (y_proba >= t).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_te, y_hat).ravel()\n",
        "    cost = C_FN * fn + C_FP * fp\n",
        "    if cost < cost_best:\n",
        "        cost_best, thr_cost = cost, float(t)\n",
        "\n",
        "# SHAP (top-20 features por importância média |SHAP|), se aplicável\n",
        "shap_img64 = None\n",
        "try:\n",
        "    is_tree_model = any(k in type(modelo).__name__.lower() for k in ['forest', 'xgb', 'xgboost', 'gradientboost', 'tree'])\n",
        "    if shap is not None and is_tree_model:\n",
        "        # Amostra para acelerar\n",
        "        amostra = min(800, X_te.shape[0])\n",
        "        X_sample = X_te.iloc[:amostra] if isinstance(X_te, pd.DataFrame) else pd.DataFrame(X_te[:amostra], columns=colunas)\n",
        "        if use_scaled and scaler is not None:\n",
        "            X_sample_infer = scaler.transform(X_sample)\n",
        "        else:\n",
        "            X_sample_infer = X_sample\n",
        "        explainer = shap.TreeExplainer(modelo)\n",
        "        shap_values = explainer.shap_values(X_sample_infer)\n",
        "        # Se lista (classes), pegar classe positiva\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_mat = np.abs(shap_values[1])\n",
        "        else:\n",
        "            shap_mat = np.abs(shap_values)\n",
        "        mean_abs = shap_mat.mean(axis=0)\n",
        "        order = np.argsort(mean_abs)[::-1][:20]\n",
        "        labels = np.array(colunas)[order]\n",
        "        vals = mean_abs[order]\n",
        "        fig_shap = plt.figure(figsize=(6,6))\n",
        "        y_pos = np.arange(len(labels))\n",
        "        plt.barh(y_pos, vals[::-1])\n",
        "        plt.yticks(y_pos, labels[::-1], fontsize=8)\n",
        "        plt.xlabel('|SHAP| médio')\n",
        "        plt.title('Top 20 atributos por importância (SHAP)')\n",
        "        shap_img64 = fig_to_base64(fig_shap)\n",
        "except Exception as e:\n",
        "    shap_img64 = None\n",
        "\n",
        "# Top 10 clientes com maior risco (conjunto de teste)\n",
        "ids = df_raw[id_col].values if id_col else np.arange(len(df_raw))\n",
        "ids_te = ids[idx_te]\n",
        "rank_df = pd.DataFrame({\n",
        "    'ID_Cliente': ids_te,\n",
        "    'Prob_Churn': y_proba\n",
        "}).sort_values('Prob_Churn', ascending=False).head(10)\n",
        "\n",
        "# HTML simples com imagens embutidas (base64)\n",
        "hoje = datetime.date.today().strftime('%d/%m/%Y')\n",
        "cm_tn, cm_fp, cm_fn, cm_tp = cm.ravel()\n",
        "html = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang='pt-br'>\n",
        "<head>\n",
        "<meta charset='utf-8'>\n",
        "<title>Relatório de Churn</title>\n",
        "<style>\n",
        " body {{ font-family: Arial, sans-serif; margin: 24px; }}\n",
        " h1, h2, h3 {{ color: #222; }}\n",
        " .kpi {{ display: flex; gap: 16px; flex-wrap: wrap; margin: 12px 0 24px; }}\n",
        " .card {{ border: 1px solid #ddd; padding: 12px 16px; border-radius: 8px; background:#fafafa; }}\n",
        " img {{ max-width: 560px; border:1px solid #eee; padding:4px; background:white; }}\n",
        " table {{ border-collapse: collapse; }}\n",
        " th, td {{ border:1px solid #ddd; padding:6px 8px; text-align:center; }}\n",
        " .grid {{ display:flex; gap:20px; flex-wrap:wrap; }}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Relatório de Churn – {hoje}</h1>\n",
        "  <div class='kpi'>\n",
        "    <div class='card'><b>ROC AUC</b><div style='font-size:20px'>{roc_auc:.3f}</div></div>\n",
        "    <div class='card'><b>PR AUC</b><div style='font-size:20px'>{pr_auc:.3f}</div></div>\n",
        "    <div class='card'><b>F1 (thr ótimo)</b><div style='font-size:20px'>{best_f1:.3f}</div></div>\n",
        "    <div class='card'><b>Threshold (F1)</b><div style='font-size:20px'>{best_thr:.3f}</div></div>\n",
        "    <div class='card'><b>Threshold (custo)</b><div style='font-size:20px'>{thr_cost:.3f}</div></div>\n",
        "    <div class='card'><b>Brier</b><div style='font-size:20px'>{brier:.3f}</div></div>\n",
        "  </div>\n",
        "\n",
        "  <h2>Matriz de Confusão (thr = {best_thr:.3f})</h2>\n",
        "  <table>\n",
        "    <tr><th></th><th>Prev. Neg</th><th>Prev. Pos</th></tr>\n",
        "    <tr><th>Real Neg</th><td>{cm_tn}</td><td>{cm_fp}</td></tr>\n",
        "    <tr><th>Real Pos</th><td>{cm_fn}</td><td>{cm_tp}</td></tr>\n",
        "  </table>\n",
        "\n",
        "  <h2>Curvas</h2>\n",
        "  <div class='grid'>\n",
        "    <div>\n",
        "      <h3>ROC</h3>\n",
        "      <img src='data:image/png;base64,{roc_img64}' />\n",
        "    </div>\n",
        "    <div>\n",
        "      <h3>Precisão-Recall</h3>\n",
        "      <img src='data:image/png;base64,{pr_img64}' />\n",
        "    </div>\n",
        "    <div>\n",
        "      <h3>Calibração</h3>\n",
        "      <img src='data:image/png;base64,{cal_img64}' />\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <h2>Top 10 clientes com maior probabilidade de churn (teste)</h2>\n",
        "  {rank_df.to_html(index=False)}\n",
        "\n",
        "  {f\"<h2>Importâncias (SHAP)</h2><img src='data:image/png;base64,\" + shap_img64 + \"' />\" if shap_img64 else \"\"}\n",
        "\n",
        "  <hr />\n",
        "  <p style='color:#666'>Relatório gerado automaticamente a partir de artefatos do modelo e avaliação no conjunto de teste reconstruído (split reproduzível, random_state=42).</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "report_path.write_text(html, encoding='utf-8')\n",
        "print(f\"Relatório atualizado salvo em: {report_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tmdSCnf7j8lg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}